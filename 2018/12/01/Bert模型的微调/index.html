<!DOCTYPE html>
<html lang=zh>
<head>
    <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
    
    <title>Bert模型的微调 | iVEGA</title>
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1" />
    <meta name="description" content="本文主要大概讲述了BERT模型的基本原理,BERT是超多参数和超大数据训练得到的预训练模型,因此模型复杂度比较高,并且可移植性比较好,因此就有了微调的环节,本文重点讲述微调的具体步骤,便于日后进行场景的转换.">
<meta property="og:type" content="article">
<meta property="og:title" content="Bert模型的微调">
<meta property="og:url" content="http://yoursite.com/2018/12/01/Bert%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%BE%AE%E8%B0%83/index.html">
<meta property="og:site_name" content="iVEGA">
<meta property="og:description" content="本文主要大概讲述了BERT模型的基本原理,BERT是超多参数和超大数据训练得到的预训练模型,因此模型复杂度比较高,并且可移植性比较好,因此就有了微调的环节,本文重点讲述微调的具体步骤,便于日后进行场景的转换.">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://blog-1-1256491104.cos.ap-chengdu.myqcloud.com/20181201133406.jpg">
<meta property="article:published_time" content="2018-12-01T05:27:05.000Z">
<meta property="article:modified_time" content="2022-05-04T16:38:19.508Z">
<meta property="article:author" content="Don&#39;t let down beauty and oneself">
<meta property="article:tag" content="BERT">
<meta property="article:tag" content="微调">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://blog-1-1256491104.cos.ap-chengdu.myqcloud.com/20181201133406.jpg">
    

    

    
        <link rel="icon" href="../../../../css/images/favicon.png" />
    
    
<link rel="stylesheet" href="../../../../libs/song-ke-fan/styles.css">

    
<link rel="stylesheet" href="../../../../libs/shui-yun/styles.css">

    
<link rel="stylesheet" href="../../../../libs/deng-xian/styles.css">

    
<link rel="stylesheet" href="../../../../libs/Microsoft-JhengHei/styles.css">

    
<link rel="stylesheet" href="../../../../libs/font-awesome5/css/fontawesome.min.css">

    
<link rel="stylesheet" href="../../../../libs/font-awesome5/css/fa-brands.min.css">

    
<link rel="stylesheet" href="../../../../libs/font-awesome5/css/fa-solid.min.css">

    
<link rel="stylesheet" href="../../../../libs/open-sans/styles.css">

    
<link rel="stylesheet" href="../../../../libs/source-code-pro/styles.css">


    
<link rel="stylesheet" href="../../../../css/style.css">


    
<script src="../../../../libs/jquery/2.1.3/jquery.min.js"></script>

    
    
        
<link rel="stylesheet" href="../../../../libs/lightgallery/css/lightgallery.min.css">

    
    
        
<link rel="stylesheet" href="../../../../libs/justified-gallery/justifiedGallery.min.css">

    
    
    
    


    


<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --><meta name="generator" content="Hexo 5.4.2"><!-- hexo-inject:begin --><!-- hexo-inject:end --></head>


<body>
    <!-- hexo-inject:begin --><!-- hexo-inject:end --><div id="container">
        <header id="header">
    <div id="header-main" class="header-inner">
        <div class="outer">
            <a href="../../../../index.html" id="logo">
                <i class="logo"></i>
                <span class="site-title">iVEGA</span>
            </a>
            <nav id="main-nav">
                
                    <a class="main-nav-link" href="../../../../.">首页</a>
                
                    <a class="main-nav-link" href="../../../../archives">归档</a>
                
                    <a class="main-nav-link" href="../../../../categories">分类</a>
                
                    <a class="main-nav-link" href="../../../../tags">标签</a>
                
                    <a class="main-nav-link" href="../../../../about">关于</a>
                
            </nav>
            
                
                <nav id="sub-nav">
                    <div class="profile" id="profile-nav">
                        <a id="profile-anchor" href="javascript:;">
                            <img class="avatar" src="../../../../css/images/avatar.png" />
                            <i class="fas fa-caret-down"></i>
                        </a>
                    </div>
                </nav>
            
            <div id="search-form-wrap">

    <form class="search-form">
        <input type="text" class="ins-search-input search-form-input" placeholder="搜索" />
        <button type="submit" class="search-form-submit"></button>
    </form>
    <div class="ins-search">
    <div class="ins-search-mask"></div>
    <div class="ins-search-container">
        <div class="ins-input-wrapper">
            <input type="text" class="ins-search-input" placeholder="想要查找什么..." />
            <span class="ins-close ins-selectable"><i class="fas fa-times-circle"></i></span>
        </div>
        <div class="ins-section-wrapper">
            <div class="ins-section-container"></div>
        </div>
    </div>
</div>
<script>
(function (window) {
    var INSIGHT_CONFIG = {
        TRANSLATION: {
            POSTS: '文章',
            PAGES: '页面',
            CATEGORIES: '分类',
            TAGS: '标签',
            UNTITLED: '(未命名)',
        },
        ROOT_URL: '/',
        CONTENT_URL: '../../../../content.json',
    };
    window.INSIGHT_CONFIG = INSIGHT_CONFIG;
})(window);
</script>

<script src="../../../../js/insight.js"></script>


</div>
        </div>
    </div>
    <div id="main-nav-mobile" class="header-sub header-inner">
        <table class="menu outer">
            <tr>
                
                    <td><a class="main-nav-link" href="../../../../.">首页</a></td>
                
                    <td><a class="main-nav-link" href="../../../../archives">归档</a></td>
                
                    <td><a class="main-nav-link" href="../../../../categories">分类</a></td>
                
                    <td><a class="main-nav-link" href="../../../../tags">标签</a></td>
                
                    <td><a class="main-nav-link" href="../../../../about">关于</a></td>
                
                <td>
                    
    <div class="search-form">
        <input type="text" class="ins-search-input search-form-input" placeholder="搜索" />
    </div>

                </td>
            </tr>
        </table>
    </div>
</header>

        <div class="outer">
            
                

<aside id="profile" class="profile-fixed">
    <div class="inner profile-inner">
        <div class="base-info profile-block">
            <img id="avatar" src="../../../../css/images/avatar.png" />
            <h2 id="name">iVEGA</h2>
            <h3 id="title"></h3>
            <span id="location"><i class="fas fa-map-marker-alt" style="padding-right: 5px"></i>Tianjin, China</span>
            <a id="follow" target="_blank" href="https://github.com/xiaopingzhong/">关注我</a>
        </div>
        <div class="article-info profile-block">
            <div class="article-info-block">
                1
                <span>文章</span>
            </div>
            <div class="article-info-block">
                2
                <span>标签</span>
            </div>
        </div>
        
    </div>
</aside>

            
            <section id="main"><article id="post-Bert模型的微调" class="article article-type-post" itemscope itemprop="blogPost">

    <div class="article-inner">
        
            
	
		<img src="https://blog-1-1256491104.cos.ap-chengdu.myqcloud.com/20181201133406.jpg" class="article-banner" />
	



        
        
            <header class="article-header">
                
    
        <h1 class="article-title" itemprop="name">
            Bert模型的微调
        </h1>
    

                
                    <div class="article-meta">
                        
    <div class="article-date">
        <i class="fas fa-calendar-alt"></i>
        <a href="">
            <time datetime="2018-12-01T05:27:05.000Z" itemprop="datePublished">2018-12-01</time>
        </a>
    </div>


                        
    <div class="article-category">
    	<i class="fas fa-folder"></i>
        <a class="article-category-link" href="../../../../categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a><i class="fas fa-angle-right"></i><a class="article-category-link" href="../../../../categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E4%BC%98%E5%8C%96/">优化</a>
    </div>

                        
    <div class="article-tag">
        <i class="fas fa-tag"></i>
        <a class="tag-link-link" href="../../../../tags/BERT/" rel="tag">BERT</a>, <a class="tag-link-link" href="../../../../tags/%E5%BE%AE%E8%B0%83/" rel="tag">微调</a>
    </div>

                    </div>
                
            </header>
        
        
   
        <div class="article-entry" itemprop="articleBody">
        
            
            <p>本文主要大概讲述了BERT模型的基本原理,BERT是超多参数和超大数据训练得到的预训练模型,因此模型复杂度比较高,并且可移植性比较好,因此就有了微调的环节,本文重点讲述微调的具体步骤,便于日后进行场景的转换.<span id="more"></span></p>
<hr>
<div class="toc">

<!-- toc -->

<ul>
<li><a href="#yi-gai-shu">一.概述</a></li>
<li><a href="#er-dai-ma-jie-xi">二.代码解析</a><ul>
<li><a href="#2-1-zhu-han-shu-bu-fen">2.1 主函数部分：</a></li>
<li><a href="#2-2-ren-wu-ming-ji-qi-fang-fa-de-ying-she">2.2 任务名及其方法的映射</a></li>
<li><a href="#2-3-gen-ju-ren-wu-ming-jin-xing-fang-fa-huo-qu">2.3 根据任务名进行方法获取</a></li>
<li><a href="#2-4-shu-ju-ji-de-zhun-bei">2.4 数据集的准备</a></li>
<li><a href="#2-5-ren-wu-fang-fa-de-jian-li">2.5 任务方法的建立</a></li>
</ul>
</li>
<li><a href="#san-yun-xing-can-shu-de-she-zhi">三.运行参数的设置</a><ul>
<li><a href="#3-1-ming-ling-xing-yun-xing">3.1 命令行运行</a></li>
<li><a href="#3-2-ben-di-yun-xing">3.2 本地运行</a></li>
</ul>
</li>
<li><a href="#si-yun-xing-jie-guo">四.运行结果</a><ul>
<li><a href="#4-1-yan-zheng-jie-guo">4.1 验证结果</a></li>
<li><a href="#4-2-ce-shi-jie-guo">4.2 测试结果</a></li>
</ul>
</li>
<li><a href="#wu-can-shu-xuan-ze">五.参数选择</a></li>
<li><a href="#liu-can-kao-wen-xian">六.参考文献:</a></li>
</ul>
<!-- tocstop -->

</div>
***
# 一.概述
![BERT模型架构](https://blog-1-1256491104.cos.ap-chengdu.myqcloud.com/20181201110547.png)
![BERT模型的输入部分](https://blog-1-1256491104.cos.ap-chengdu.myqcloud.com/20181201110614.png)
　　今年是迁移学习进步比较大的一年，典型的代表就是BERT模型,BERT模型就是Bidirectional Encoder Representation from Transformers，即Transformer的双向编码,通过超大数据、巨大模型、和极大的计算开销训练而成.就是一个预训练,后期通过微调(Fine-Tuning)来适应不同的NLP任务,其主要思想就是通过双向编码来理解文本的语义(词与词之间的关系)--**输入主要有三个部分**:词语本身的表示,词的位置信息,还有一个词在句子中的表示,三个相加构成BERT模型的输入.之后通过双向编码(也就是同时利用当前位置前面的词和后面的词两部分信息),同时借助随机遮掩的方法,增加不确定,提高模型的复杂度,加上借助超大数据集,平衡数据和模型的关系,最终得到一个预训练的模型.其实就是得到了一个提取文本特征的编码器,这个其实就是迁移学习的典型体现:实现了较为复杂的特征提取,之后根据自己的需求,编写对应的具体的NLP任务(一般设置好数据格式和数据的读写即可),之后进行调试超参数,得到一个较高准确率的解码器,这个就是BERT模型微调的过程
　　因为BERT模型已经有训练好的中文模型,因此我们就没有必要再次进行预训练,因为耗时非常大,因此我们就可以根据这个预训练的模型进行微调,实现模型应用场景的迁移(也就是迁移学习的思想)
　　本文以分类任务的迁移进行说明.因此主要修改地方为:run_classifier.py
# 二.代码解析
## 2.1 主函数部分：
<figure class="highlight pf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">if __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">  <span class="comment"># 模型的输入文件地址/目录,之后有专门的方法读取文件也就是Processor做的事情</span></span><br><span class="line">  <span class="keyword">flags</span>.mark_flag_as_required(<span class="string">&quot;input_file&quot;</span>)</span><br><span class="line">  <span class="comment"># 模型的配置文件的路径</span></span><br><span class="line">  <span class="keyword">flags</span>.mark_flag_as_required(<span class="string">&quot;bert_config_file&quot;</span>)</span><br><span class="line">  <span class="comment"># 模型的输出文件的路径</span></span><br><span class="line">  <span class="keyword">flags</span>.mark_flag_as_required(<span class="string">&quot;output_dir&quot;</span>)</span><br><span class="line">  <span class="comment"># 模型运行</span></span><br><span class="line">  tf.app.run()</span><br></pre></td></tr></table></figure>
## 2.2 任务名及其方法的映射
　　以字典的形式完成映射
<figure class="highlight mipsasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 任务的名称与任务方法名</span></span><br><span class="line"> processors = &#123;</span><br><span class="line">     <span class="string">&quot;cola&quot;</span>: ColaProcessor,</span><br><span class="line">     <span class="string">&quot;mnli&quot;</span>: MnliProcessor,</span><br><span class="line">     <span class="string">&quot;mrpc&quot;</span>: MrpcProcessor,</span><br><span class="line">     <span class="string">&quot;xnli&quot;</span>: XnliProcessor,</span><br><span class="line">     ＃自定义的方法</span><br><span class="line">     <span class="string">&quot;vega&quot;</span>: <span class="keyword">MoveProcessor</span></span><br><span class="line"><span class="keyword"></span> &#125;</span><br></pre></td></tr></table></figure>
　　不同的方法对应处理不同的数据集,这个要搞清楚.如MrpcProcessor这个方法是对MRPC训练集进行模型训练,验证,测试.
## 2.3 根据任务名进行方法获取
<figure class="highlight vbnet"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># task_name <span class="built_in">is</span> used <span class="keyword">to</span> <span class="keyword">select</span> processor,<span class="built_in">And</span> the name <span class="built_in">is</span> lowercase</span><br><span class="line"> task_name = FLAGS.task_name.lower()</span><br><span class="line"> # <span class="keyword">if</span> task_name <span class="keyword">as</span> a <span class="keyword">key</span> don<span class="comment">&#x27;t match with Processor which is type of dict ,os will print error</span></span><br><span class="line"> <span class="keyword">if</span> task_name <span class="built_in">not</span> <span class="keyword">in</span> processors:</span><br><span class="line">   raise ValueError(<span class="string">&quot;Task not found: %s&quot;</span> % (task_name))</span><br><span class="line"> # <span class="keyword">if</span> exist,we will <span class="keyword">get</span> the processor which aims <span class="keyword">to</span> deal <span class="keyword">with</span> data</span><br><span class="line"> processor = processors[task_name]()</span><br></pre></td></tr></table></figure>
## 2.4 数据集的准备
　　主要是有三个数据集：训练集，验证集，测试集，自定义数据集的格式需要和原有的数据集格式最好一直，这样能减轻开发的成本．便于照猫画虎．类别与句子用`\t`即tab键,隔开,具体如下：
![数据集的组成](https://blog-1-1256491104.cos.ap-chengdu.myqcloud.com/20181201125219.png)
注意:
　　数据集的**格式最好是utf-8(无BOM)格式存储**,否则读取容易出问题.
　　各个阶段的数据量大小最好呈现为：７：２：１，逐步缩小（我的就不太标准）
（１）训练集train.tsv:
<figure class="highlight gcode"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">0</span>	compa<span class="symbol">ny1</span>获得了什么奖</span><br><span class="line"><span class="number">1</span>	prize是哪个公司获得的</span><br><span class="line"><span class="number">3</span>	prize的证书上编号是多少</span><br><span class="line"><span class="number">3</span>	我想查看prize的证书编号</span><br><span class="line"><span class="number">2</span>	compa<span class="symbol">ny1</span>与compa<span class="symbol">ny2</span>的关系是怎样的</span><br><span class="line"><span class="number">0</span>	compa<span class="symbol">ny1</span>有哪些奖</span><br><span class="line"><span class="number">3</span>	我想知道prize的证书编号</span><br><span class="line"><span class="number">2</span>	compa<span class="symbol">ny1</span>与compa<span class="symbol">ny2</span>的联系</span><br><span class="line"><span class="number">1</span>	prize是授予给哪个公司的</span><br><span class="line"><span class="number">1</span>	prize是表彰给哪个公司的</span><br><span class="line"><span class="number">2</span>	compa<span class="symbol">ny1</span>与compa<span class="symbol">ny2</span>是什么关系</span><br><span class="line"><span class="number">3</span>	prize的证书编号是多少</span><br></pre></td></tr></table></figure>
（２）验证集dev.tsv:
<figure class="highlight gcode"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">2</span>	compa<span class="symbol">ny1</span>与compa<span class="symbol">ny2</span>之间的关系</span><br><span class="line"><span class="number">3</span>	prize的编号是多少</span><br><span class="line"><span class="number">2</span>	compa<span class="symbol">ny1</span>与compa<span class="symbol">ny2</span>有怎样的联系</span><br><span class="line"><span class="number">1</span>	prize属于哪个公司</span><br><span class="line"><span class="number">1</span>	prize是颁发给哪个公司的</span><br><span class="line"><span class="number">1</span>	哪个公司获取的奖项是prize</span><br><span class="line"><span class="number">0</span>	compa<span class="symbol">ny1</span>荣获哪些奖</span><br><span class="line"><span class="number">3</span>	我想知道prize上的证书编号</span><br></pre></td></tr></table></figure>
（３）测试集test.tsv
<figure class="highlight gcode"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">1</span>	prize的奖项由哪个公司得到</span><br><span class="line"><span class="number">0</span>	有哪些奖是compa<span class="symbol">ny1</span>获得的</span><br><span class="line"><span class="number">2</span>	compa<span class="symbol">ny1</span>与compa<span class="symbol">ny2</span>是怎样的关系</span><br><span class="line"><span class="number">0</span>	compa<span class="symbol">ny1</span>获取了哪些奖</span><br><span class="line"><span class="number">3</span>	我想查看prize上的编号</span><br></pre></td></tr></table></figure>
## 2.5 任务方法的建立
　　方法的建立是根据数据集的情况来建立的,我的情况是:数据集的标签为４个；数据格式为：标签＋'\t'+句子；数据集有三个．自定义方法如下：
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#这个就是自定义的方法,针对自己的数据集设定的.</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MoveProcessor</span>(<span class="title class_ inherited__">DataProcessor</span>):</span><br><span class="line">  <span class="string">&quot;&quot;&quot;Processor for the move data set .&quot;&quot;&quot;</span></span><br><span class="line">  <span class="keyword">def</span> <span class="title function_">get_train_examples</span>(<span class="params">self, data_dir</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;See base class.&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">return</span> self._create_examples(</span><br><span class="line">        self._read_tsv(os.path.join(data_dir, <span class="string">&quot;train.tsv&quot;</span>)), <span class="string">&quot;train&quot;</span>)</span><br><span class="line"></span><br><span class="line">  <span class="keyword">def</span> <span class="title function_">get_dev_examples</span>(<span class="params">self, data_dir</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;See base class.&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">return</span> self._create_examples(</span><br><span class="line">        self._read_tsv(os.path.join(data_dir, <span class="string">&quot;dev.tsv&quot;</span>)), <span class="string">&quot;dev&quot;</span>)</span><br><span class="line"></span><br><span class="line">  <span class="keyword">def</span> <span class="title function_">get_test_examples</span>(<span class="params">self, data_dir</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;See base class.&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">return</span> self._create_examples(</span><br><span class="line">        self._read_tsv(os.path.join(data_dir, <span class="string">&quot;test.tsv&quot;</span>)), <span class="string">&quot;test&quot;</span>)</span><br><span class="line"></span><br><span class="line">  <span class="keyword">def</span> <span class="title function_">get_labels</span>(<span class="params">self</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;See base class.&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">return</span> [<span class="string">&quot;0&quot;</span>, <span class="string">&quot;1&quot;</span>, <span class="string">&quot;2&quot;</span>, <span class="string">&quot;3&quot;</span>]</span><br><span class="line"></span><br><span class="line"> <span class="comment">#设置统一的读取转换格式,便于不同训练集的调用</span></span><br><span class="line">  <span class="keyword">def</span> <span class="title function_">_create_examples</span>(<span class="params">self, lines, set_type</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Creates examples for the training and dev sets.&quot;&quot;&quot;</span></span><br><span class="line">    examples = []</span><br><span class="line">    <span class="keyword">for</span> (i, line) <span class="keyword">in</span> <span class="built_in">enumerate</span>(lines):</span><br><span class="line">      guid = <span class="string">&quot;%s-%s&quot;</span> % (set_type, i)</span><br><span class="line">      <span class="keyword">if</span> set_type == <span class="string">&quot;test&quot;</span>:</span><br><span class="line">        text_a = tokenization.convert_to_unicode(line[<span class="number">0</span>])</span><br><span class="line">        label = <span class="string">&quot;0&quot;</span></span><br><span class="line">      <span class="keyword">else</span>:</span><br><span class="line">        text_a = tokenization.convert_to_unicode(line[<span class="number">1</span>])</span><br><span class="line">        label = tokenization.convert_to_unicode(line[<span class="number">0</span>])</span><br><span class="line">      examples.append(</span><br><span class="line">          InputExample(guid=guid, text_a=text_a, text_b=<span class="literal">None</span>, label=label))</span><br><span class="line">    <span class="keyword">return</span> examples</span><br></pre></td></tr></table></figure>
　　从上面的程序也可以看出processor的方法主要是进行数据的读取,基本方法就是使用`_create_examples()`奠定读取的方法.
# 三.运行参数的设置
　　由于本地上以命令行运行有些问题，需要在Google的colab中才能正常运行，本文同时讲解命令行的形式和本地的形式
### 3.1 命令行运行
<figure class="highlight jboss-cli"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!是代表在linux下运行</span></span><br><span class="line">!python run_classifier.py \</span><br><span class="line">    <span class="comment">#任务的名称</span></span><br><span class="line">	<span class="params">--task_name=vega</span> \</span><br><span class="line">	<span class="comment">#是否需要进行训练</span></span><br><span class="line">    <span class="params">--do_train=true</span> \</span><br><span class="line">    <span class="comment">#是否需要进行验证</span></span><br><span class="line">    <span class="params">--do_eval=true</span> \</span><br><span class="line">    <span class="comment">#是否需要进行测试,false时不会进行测试,true时则会优先使用已经存在的模型,</span></span><br><span class="line">    <span class="comment">#没模型的话,则会从头训练,直至模型保存.</span></span><br><span class="line">    <span class="params">--do_predict=false</span></span><br><span class="line">    <span class="comment">#数据文件的目录,训练之前需要将训练集,验证集,测试集的文件准备好</span></span><br><span class="line">    <span class="params">--data_dir=data</span> \</span><br><span class="line">    <span class="comment">#下面三个colab会调用谷歌自家保存的预训练模型,不需要自己上传,也可以自己上传(比较耗时)</span></span><br><span class="line">    <span class="params">--vocab_file=gs</span>:<span class="string">//cloud-tpu-checkpoints/bert/uncased_L-24_H-1024_A-16/vocab.txt</span> \</span><br><span class="line">    <span class="params">--bert_config_file=gs</span>:<span class="string">//cloud-tpu-checkpoints/bert/uncased_L-24_H-1024_A-16/bert_config.json</span> \</span><br><span class="line">    <span class="params">--init_checkpoint=gs</span>:<span class="string">//cloud-tpu-checkpoints/bert/uncased_L-24_H-1024_A-16/bert_model.ckpt</span> \</span><br><span class="line">    <span class="comment">#分词时一个词语的最大长度</span></span><br><span class="line">    <span class="params">--max_seq_length=16</span> \</span><br><span class="line">    <span class="comment">#批量训练的的大小每32个为一批</span></span><br><span class="line">    <span class="params">--train_batch_size=32</span> \</span><br><span class="line">    <span class="comment">#学习率(一般不动)</span></span><br><span class="line">    <span class="params">--learning_rate=2e-5</span> \</span><br><span class="line">    <span class="comment">#轮询的次数:8次</span></span><br><span class="line">    <span class="params">--num_train_epochs=8</span>.0 \</span><br><span class="line">    <span class="comment">#模型及其各个阶段的结果的保存目录</span></span><br><span class="line">    <span class="params">--output_dir=output</span> \</span><br></pre></td></tr></table></figure>
　　上面代码是在colab中的运行的方法,根据自己的需要进行修改,之后直接粘贴复制即可．
### 3.2 本地运行
　　本地运行主要是在run_classifier.py中,修改的情况为:
<figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 设置常量.便于后期修改</span></span><br><span class="line"><span class="attribute">DATA_DIR</span>=<span class="string">&quot;E:/Project/bert/Before/data/&quot;</span></span><br><span class="line"><span class="attribute">MODEL_DIR</span>=<span class="string">&quot;E:/Project/bert/Before/PreTrainingModel/&quot;</span></span><br><span class="line"><span class="attribute">OUTPUT_DIR</span>=<span class="string">&quot;E:/Project/bert/Before/output/&quot;</span></span><br><span class="line"><span class="comment">#参数修改(其实还有很多,找几个关键的参数修改即可)</span></span><br><span class="line"><span class="string">&quot;data_dir&quot;</span>, DATA_DIR,</span><br><span class="line"><span class="string">&quot;bert_config_file&quot;</span>,MODEL_DIR+<span class="string">&quot;bert_config.json&quot;</span>,</span><br><span class="line"><span class="string">&quot;task_name&quot;</span>, <span class="string">&quot;vega&quot;</span>,</span><br><span class="line"><span class="string">&quot;vocab_file&quot;</span>, MODEL_DIR+<span class="string">&quot;vocab.txt&quot;</span>,</span><br><span class="line"><span class="string">&quot;init_checkpoint&quot;</span>, MODEL_DIR+<span class="string">&quot;bert_model.ckpt&quot;</span>,</span><br><span class="line"><span class="string">&quot;max_seq_length&quot;</span>, 16,</span><br><span class="line"><span class="string">&quot;do_train&quot;</span>,<span class="literal">True</span>,</span><br><span class="line"><span class="string">&quot;do_eval&quot;</span>, <span class="literal">True</span>,</span><br><span class="line"><span class="string">&quot;do_predict&quot;</span>, <span class="literal">True</span>,</span><br><span class="line"><span class="string">&quot;train_batch_size&quot;</span>,32,</span><br><span class="line"><span class="string">&quot;eval_batch_size&quot;</span>,6, </span><br><span class="line"><span class="string">&quot;predict_batch_size&quot;</span>, 2, </span><br><span class="line"><span class="string">&quot;learning_rate&quot;</span>, 5e-5,</span><br><span class="line"><span class="string">&quot;num_train_epochs&quot;</span>, 8.0,</span><br><span class="line"><span class="string">&quot;warmup_proportion&quot;</span>, 0.1,</span><br></pre></td></tr></table></figure>
# 四.运行结果
## 4.1 验证结果
屏幕上也会输出验证结果情况:
![屏幕输出结果图](https://blog-1-1256491104.cos.ap-chengdu.myqcloud.com/20181201135011.png)
　　验证结果保存在output目录的eval_results.txt,如下图:
![验证结果图](https://blog-1-1256491104.cos.ap-chengdu.myqcloud.com/20181201131357.png)
## 4.2 测试结果
　　测试结果保存在output目录的test_results.tsv:
![测试结果](https://blog-1-1256491104.cos.ap-chengdu.myqcloud.com/20181201131301.png)
　　上表中:每行代表每类的概率,如第一行则代表第二类的概率最大,为`0.30405113`,所以其对应的标签为2.以此类推
# 五.参数选择
以下是本次调整的参数.
<figure class="highlight 1c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;max_seq_length&quot;</span>, <span class="number">16</span>,</span><br><span class="line"><span class="string">&quot;train_batch_size&quot;</span>,<span class="number">32</span>,</span><br><span class="line"><span class="string">&quot;eval_batch_size&quot;</span>,<span class="number">6</span>,</span><br><span class="line"><span class="string">&quot;predict_batch_size&quot;</span>, <span class="number">2</span>,</span><br><span class="line"><span class="string">&quot;learning_rate&quot;</span>, <span class="number">5</span>e-<span class="number">5</span>,</span><br><span class="line"><span class="string">&quot;num_train_epochs&quot;</span>, <span class="number">8.0</span>,</span><br><span class="line"><span class="string">&quot;warmup_proportion&quot;</span>, <span class="number">0.1</span>,</span><br><span class="line"><span class="string">&quot;save_checkpoints_steps&quot;</span>, <span class="number">1000</span>,</span><br><span class="line"><span class="string">&quot;iterations_per_loop&quot;</span>, <span class="number">1000</span>,</span><br></pre></td></tr></table></figure>
# 六.参考文献:
　　❋[谷歌最强NLP模型BERT解读](https://news.cnblogs.com/mv?id=610293)
　　❋[BERT的理解](https://blog.csdn.net/yangfengling1023/article/details/84025313)
　　❋[BERT模型fine-tuning代码解析（一）](https://blog.csdn.net/u014108004/article/details/84142035)
            
            
<div style="padding: 15px;
    margin-bottom: 20px;
    border: 1px solid transparent;
    border-radius: 4px;
    background-color: #f5f5f5;
    padding: 7px;
    margin-top: 10px;
    margin-bottom: 20px;
    margin-left: 10px;
    margin-right: 10px;
    color: #565a5f;
    line-height: 2em;
">
        <div class="copyright-left">
            <i class="fa fa-lightbulb"></i>
           		 本文由 <a target="_blank" rel="noopener" href="https://www.zhongxiaoping.cn/index.html">iVEGA</a> 创作，采用
            <a href="http://creativecommons.org/licenses/by/3.0/cn" target="_blank" rel="external">CC BY 3.0 CN协议</a> 进行许可。
            可自由转载、引用，但需署名作者且注明文章出处 http://yoursite.com/2018/12/01/Bert%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%BE%AE%E8%B0%83/index.html <br>
        </div>
        <div style="clear:both;height:0px;"></div>
</div>

        
        </div>
        <span style="float:right">
        <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    
    本文阅读量：<span id="busuanzi_value_page_pv"></span>次

</span>
        <footer class="article-footer">
            <div class="share-container">



</div>

            
    

        </footer>
        
        
    </div>
    
        

    

</article>


    
    
        <section id="comments">
    <div id="valine-thread"></div>
</section>
    

</section>
            
                
<aside id="sidebar">
   
        
    <div class="widget-wrap">
        <h3 class="widget-title">最新文章</h3>
        <div class="widget">
            <ul id="recent-post" class="">
                
                    <li>
                        
                        <div class="item-thumbnail">
                            <a href="" class="thumbnail">
    
    
        <span style="background-image:url(https://blog-1-1256491104.cos.ap-chengdu.myqcloud.com/20181201133406.jpg)" alt="Bert模型的微调" class="thumbnail-image"></span>
    
</a>

                        </div>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="../../../../categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a><i class="fas fa-angle-right"></i><a class="article-category-link" href="../../../../categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E4%BC%98%E5%8C%96/">优化</a></p>
                            <p class="item-title"><a href="" class="title">Bert模型的微调</a></p>
                            <p class="item-date"><time datetime="2018-12-01T05:27:05.000Z" itemprop="datePublished">2018-12-01</time></p>
                        </div>
                    </li>
                
            </ul>
        </div>
    </div>

    
        
    <div class="widget-wrap">
        <h3 class="widget-title">分类</h3>
        <div class="widget">
            <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="../../../../categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a><span class="category-list-count">1</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="../../../../categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E4%BC%98%E5%8C%96/">优化</a><span class="category-list-count">1</span></li></ul></li></ul>
        </div>
    </div>

    
        
    <div class="widget-wrap">
        <h3 class="widget-title">归档</h3>
        <div class="widget">
            <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="../../../../archives/2018/12/">十二月 2018</a><span class="archive-list-count">1</span></li></ul>
        </div>
    </div>

    
        
    <div class="widget-wrap">
        <h3 class="widget-title">标签</h3>
        <div class="widget">
            <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="../../../../tags/BERT/" rel="tag">BERT</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="../../../../tags/%E5%BE%AE%E8%B0%83/" rel="tag">微调</a><span class="tag-list-count">1</span></li></ul>
        </div>
    </div>

    
        
    <div class="widget-wrap">
        <h3 class="widget-title">标签云</h3>
        <div class="widget tagcloud">
            <a href="../../../../tags/BERT/" style="font-size: 10px;">BERT</a> <a href="../../../../tags/%E5%BE%AE%E8%B0%83/" style="font-size: 10px;">微调</a>
        </div>
    </div>

    
        
    <div class="widget-wrap widget-list">
        <h3 class="widget-title">链接</h3>
        <div class="widget">
            <ul>
                
                    <li>
                        <a target="_blank" rel="noopener" href="http://xueshu.baidu.com/">百度学术</a>
                    </li>
                
                    <li>
                        <a target="_blank" rel="noopener" href="https://www.appinn.com/category/windows/">小众软件</a>
                    </li>
                
            </ul>
        </div>
    </div>


    
    <div id="toTop" class="fas fa-angle-up"></div>
</aside>

            
        </div>
        <footer id="footer">
<div class="outer">
        <div id="footer-info" class="inner">
            &copy; 2022 Don&#39;t let down beauty and oneself<br>
               <!-- 首先引入统计用的js，然后编写相应的统计代码 -->
               <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
               访问量<span id="busuanzi_value_site_pv"></span>次(◕ܫ◕)访客数<span id="busuanzi_value_site_uv"></span>人
               <!-- 注释掉Powered by，Theme by的显示。-->
               <!-- Powered by <a href="http://blog.kimzing.com/" target="_blank">Kim</a>. Theme by <a target="_blank" rel="noopener" href="http://github.com/ppoffice">PPOffice</a> -->
        </div>
    </div>


<span id="timeDate">载入天数...</span><span id="times">载入时分秒...</span>
<script>
    var now = new Date(); 
    function createtime() { 
        var grt= new Date("06/18/2018 12:49:00");//此处修改你的建站时间或者网站上线时间 
        now.setTime(now.getTime()+250); 
        days = (now - grt ) / 1000 / 60 / 60 / 24; dnum = Math.floor(days); 
        hours = (now - grt ) / 1000 / 60 / 60 - (24 * dnum); hnum = Math.floor(hours); 
        if(String(hnum).length ==1 ){hnum = "0" + hnum;} minutes = (now - grt ) / 1000 /60 - (24 * 60 * dnum) - (60 * hnum); 
        mnum = Math.floor(minutes); if(String(mnum).length ==1 ){mnum = "0" + mnum;} 
        seconds = (now - grt ) / 1000 - (24 * 60 * 60 * dnum) - (60 * 60 * hnum) - (60 * mnum); 
        snum = Math.round(seconds); if(String(snum).length ==1 ){snum = "0" + snum;} 
        document.getElementById("timeDate").innerHTML = "本站已安全运行 "+dnum+" 天 "; 
        document.getElementById("times").innerHTML = hnum + " 小时 " + mnum + " 分 " + snum + " 秒"; 
    } 
setInterval("createtime()",250);
</script>


</footer>
        
    
    <script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
    <script src="//cdn.jsdelivr.net/gh/xcss/valine@v1.1.6/dist/Valine.min.js"></script>
    <script>
        new Valine({
            el: '#valine-thread' ,
            notify:true,
            verify:false,
            app_id: 'z4tuSWjbVK2A9f5fL9X79TW3-gzGzoHsz',
            app_key: 'MToHqxs5eJrVXM95jc5FAOgz',
            placeholder: '输入问题,咱们共同交流,一起进步'
        });
    </script>




    
        
<script src="../../../../libs/lightgallery/js/lightgallery.min.js"></script>

        
<script src="../../../../libs/lightgallery/js/lg-thumbnail.min.js"></script>

        
<script src="../../../../libs/lightgallery/js/lg-pager.min.js"></script>

        
<script src="../../../../libs/lightgallery/js/lg-autoplay.min.js"></script>

        
<script src="../../../../libs/lightgallery/js/lg-fullscreen.min.js"></script>

        
<script src="../../../../libs/lightgallery/js/lg-zoom.min.js"></script>

        
<script src="../../../../libs/lightgallery/js/lg-hash.min.js"></script>

        
<script src="../../../../libs/lightgallery/js/lg-share.min.js"></script>

        
<script src="../../../../libs/lightgallery/js/lg-video.min.js"></script>

    
    
        
<script src="../../../../libs/justified-gallery/jquery.justifiedGallery.min.js"></script>

    

    <!-- Edit here -->
    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
    <!-- MathJax **处理 HTML/CSS 输出的配置**-->
    "HTML-CSS": { 
    <!--设置字体（preferredFont、availableFonts）-->
        preferredFont: "TeX", 
        availableFonts: ["STIX","TeX"], 
        <!--换行（linebreaking）-->
        linebreaks: { automatic:true }, 
        <!--渲染延迟（EqnChunk）-->
        EqnChunk: (MathJax.Hub.Browser.isMobile ? 10 : 50) 
    },
    <!--这部分是 tex2jax.js 预处理程序需要的配置-->
    tex2jax: { 
    <!--设置为可以使用“公式”或“\\( 公式 )\\”在行内内联公式-->
        inlineMath: [ ["$", "$"], ["\\(","\\)"] ], 
        <!--设置是否允许使用 \$ 来 escape 一些信息。-->
        processEscapes: true, 
        <!--　ignoreClass 用于设置具有哪些 css class 的标签不用 tex2jax 预处理。-->
        ignoreClass: "tex2jax_ignore|dno",
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    <!--处理 TeX 及相关插件的输入的-->
    TeX: {  
    <!--加上公式编号和宏的功能（noUndefined）-->
        equationNumbers: { autoNumber: "AMS" },
        noUndefined: { attributes: { mathcolor: "red", mathbackground: "#FFEEEE", mathsize: "90%" } }, 
        Macros: { href: "{}" } 
    },
    <!--属于通用配置，用于控制是否显示加载信息。-->
    messageStyle: "none"
    }); 
</script>
<!-- 给MathJax元素添加has-jax class -->
<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>
<!-- 通过连接CDN加载最新的MathJax的js代码 -->
    
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML.js"></script>





<!-- Custom Scripts -->

<script src="../../../../js/main.js"></script>


    </div><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</body>
</html>